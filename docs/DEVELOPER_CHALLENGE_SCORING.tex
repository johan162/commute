% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\documentclass[]{article}
\usepackage[a4paper, margin=1in]{geometry}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{2} % number sections and subsections
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi

% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}

\title{Scoring Methodology for Confidence Interval Estimation Challenge}
\author{Johan Persson }

\begin{document}

\maketitle

\begin{center}
\subsection*{Abstract}\label{abstract}
\end{center}

\begin{quote}
\itshape
We present a comprehensive scoring system for evaluating the quality of
subjective confidence interval (CI) estimates in the context of commute
time prediction. The methodology employs a multi-component penalty
framework that simultaneously optimizes for interval precision, coverage
accuracy, confidence calibration, and distributional balance. Drawing
inspiration from Brier scoring principles, our approach extends
traditional binary forecast evaluation to continuous interval
estimation, incorporating quadratic penalties for deviations from target
specifications. The system is designed to discourage gaming strategies
while rewarding honest self-assessment and well-calibrated predictions.
We demonstrate that the proposed scoring function effectively balances
competing objectives through weighted penalty terms, with specific
emphasis on ensuring both aggregate coverage (90\% target) and tail
symmetry (5\% in each tail).
\end{quote}

\section{Introduction}\label{introduction}

\subsection{Problem Statement}\label{problem-statement}

Accurate estimation of confidence intervals represents a fundamental
challenge in probabilistic forecasting. In practical applications such
as commute time prediction, users must balance competing objectives:
intervals that are too narrow fail to capture sufficient observations,
while excessively wide intervals, though technically correct, provide
limited actionable information. Traditional scoring rules for
probabilistic forecasts, such as the Brier score for binary events, do
not directly extend to interval estimation problems with multiple
quality dimensions.

\subsection{Challenge Specification}\label{challenge-specification}

Participants are asked to estimate a 90\% confidence interval for their
commute duration based on historical observations. Specifically, given a
dataset \(\mathcal{D} = \{x_1, x_2, \ldots, x_n\}\) of \(n \geq 20\)
observed commute times, participants must specify:

\begin{itemize}
\tightlist
\item
  \textbf{Interval bounds:} \([L, H]\) where \(L\) represents the lower
  bound and \(H\) the upper bound (in seconds)
\item
  \textbf{Confidence level:} \(c \in [5, 10]\) representing the
  participant's subjective confidence that their interval represents a
  true 90\% CI
\end{itemize}

The target specification is a 90\% confidence interval, corresponding to a significance level of
\(\alpha = 0.10\) with \(\alpha/2 = 0.05\) in each tail under a
symmetric distribution assumption (z-score \(\pm 1.645\)).

\section{Theoretical Foundation}\label{theoretical-foundation}

\subsection{Brier Score and Mean Squared
Error}\label{brier-score-and-mean-squared-error}

The Brier score, introduced by Glenn W. Brier (1950), evaluates
probabilistic forecasts for binary events through mean squared error:

\[
\text{BS} = \frac{1}{n}\sum_{i=1}^{n}(f_i - o_i)^2
\]

where \(f_i\) is the forecast probability and \(o_i \in \{0,1\}\) is the
observed outcome. This quadratic penalty structure has desirable
theoretical properties: it is strictly proper (encourages honest
reporting), decomposable into calibration and refinement components, and
provides smooth gradients that appropriately weight larger errors more
heavily than smaller ones.

\subsection{Extension to Interval
Estimation}\label{extension-to-interval-estimation}

Our scoring methodology adapts the quadratic penalty principle to
interval estimation by decomposing the problem into five measurable
quality dimensions, each contributing a penalty term to the final score.
The total score \(S\) is expressed as:

\[
S = P_{\text{precision}} + P_{\text{miss}} + P_{\text{over}} + P_{\text{calib}} + P_{\text{balance}}
\]

where lower scores indicate superior performance. This additive
structure allows independent tuning of penalty weights while maintaining
interpretability.

\section{Scoring Components}\label{scoring-components}

\subsection{Precision Penalty}\label{interval-width-penalty}

\textbf{Definition:}

Let the sorted dataset be $\mathcal{D}_{\text{sorted}} = \{x_{(1)}, x_{(2)}, \ldots, x_{(n)}\}$ where $x_{(1)} \leq x_{(2)} \leq \cdots \leq x_{(n)}$.

Define the sample percentiles:
\begin{itemize}
\tightlist
\item
  $p_5 = x_{(\lfloor 0.05n \rfloor)}$ (5th percentile)
\item
  $p_{95} = x_{(\lfloor 0.95n \rfloor)}$ (95th percentile)
\end{itemize} 

Then:

\[
P_{\text{precision}} = (L - p_5)^2 + (H - p_{95})^2
\]


\textbf{Rationale:} The precision penalty measures how accurately the participant estimates the empirical 90\% confidence interval boundaries. 
By penalizing squared deviations from the actual sample percentiles, this component rewards accurate boundary estimation regardless of the 
inherent variability of the commute times. This ensures fairness: participants with highly variable commutes (wide true intervals) are not 
penalized relative to those with consistent commutes (narrow true intervals). The penalty measures \textit{orecasting skill}, 
not the characteristics of the underlying data.


\textbf{Properties:} 
\begin{itemize}
\tightlist
\item
Quadratic in estimation error (Brier-inspired)
\item
Scale-independent: measures relative accuracy
\item
Fair across different commute variability levels
\item
Zero penalty for perfect percentile matching
\end{itemize}

\subsection{Miss Penalty}\label{miss-penalty}

\textbf{Definition:} For each observation \(x_i \in \mathcal{D}\),
define the miss function:

\[
m(x_i) = \begin{cases}
(x_i - L)^2 & \text{if } x_i < L \\
(x_i - H)^2 & \text{if } x_i > H \\
0 & \text{if } L \leq x_i \leq H
\end{cases}
\]

Let \(\mathcal{M} = \{m(x_i) : m(x_i) > 0\}\) be the sorted set of
non-zero misses, and
\(\mathcal{M}' = \mathcal{M}_{[\lfloor 0.1|\mathcal{M}|\rfloor:]}\) be
\(\mathcal{M}\) with the smallest 10\% removed. Then:

\[
P_{\text{miss}} = \frac{1}{n}\sum_{m \in \mathcal{M}'} m
\]

\textbf{Rationale:} The squared distance formulation borrows directly
from Brier's mean squared error principle, penalizing outliers more
severely than near-misses. The 10\% trimming provides tolerance for the
90\% CI specification, effectively ignoring the smallest violations that
fall within expected coverage gaps.

\textbf{Properties:} 
\begin{itemize}
\tightlist
\item
Quadratic in miss distance (Brier-inspired) 
\item
Normalized by total sample size \(n\)
\item
Robust to extreme outliers through 10\% trimming
\item
Invariant to confidence level (separated from calibration)
\end{itemize}


\subsection{Overcoverage Penalty}\label{overcoverage-penalty}

\textbf{Definition:} Let
\(C_{\text{actual}} = \frac{100}{n}|\{x_i : L \leq x_i \leq H\}|\) be
the empirical coverage percentage. With target coverage
\(C_{\text{target}} = 90\):

\[
P_{\text{over}} = \begin{cases}
0.5 \cdot (H - L) \cdot \left(\frac{C_{\text{actual}} - 90}{10}\right)^2 & \text{if } C_{\text{actual}} > 95 \\
0 & \text{otherwise}
\end{cases}
\]

\textbf{Rationale:} This component prevents a trivial gaming strategy
where participants select arbitrarily wide intervals to guarantee
coverage. The penalty activates only for coverage exceeding 95\%
(allowing 5\% tolerance), and scales quadratically with both excess
coverage and interval width. The multiplicative width term ensures that
wasteful intervals incur proportionally higher costs.

\textbf{Properties:} 

\begin{itemize}
\item
Activates beyond 5\% tolerance threshold
\item
Quadratic in excess coverage
\item
Proportional to interval width
\item
Coefficient 0.5 balances impact relative to other penalties
\end{itemize}


\subsection{Confidence Calibration
Penalty}\label{confidence-calibration-penalty}

\textbf{Definition:} Define:

\begin{align}
P_{\text{below}} &= \frac{100}{n}|\{x_i : x_i < L\}| \\
P_{\text{above}} &= \frac{100}{n}|\{x_i : x_i > H\}| \\
P_{\text{outside}} &= P_{\text{below}} + P_{\text{above}} \\
\Delta_{\text{cov}} &= |P_{\text{outside}} - 10|
\end{align}

Map coverage deviation to ideal confidence:

\[
c_{\text{ideal}} = \max\left(5, 10 - \frac{\Delta_{\text{cov}}}{10}\right)
\]

Let \(\Delta_c = |c - c_{\text{ideal}}|\) be the confidence mismatch.
For \(c = 10\) (claiming perfection), define tail imbalance:

\[
\Delta_{\text{tail}} = |P_{\text{below}} - 5| + |P_{\text{above}} - 5|
\]

Then:

\[
P_{\text{calib}} = \begin{cases}
3.0 \cdot (H - L) \cdot \left(\frac{\Delta_{\text{cov}} + \Delta_{\text{tail}}}{5}\right)^2 & \text{if } c = 10 \text{ and } (\Delta_{\text{cov}} > 1 \text{ or } \Delta_{\text{tail}} > 2) \\
2.0 \cdot (H - L) \cdot \left(\frac{\Delta_c}{5}\right)^2 & \text{otherwise}
\end{cases}
\]

\textbf{Rationale:} Confidence calibration rewards honest
self-assessment. The ideal confidence mapping establishes that perfect
10\% outside coverage merits maximum confidence (10), while
progressively poorer coverage should correspond to lower claimed
confidence. The special case for \(c = 10\) implements strict
requirements: claiming certainty of perfection requires both accurate
total coverage (\(\Delta_{\text{cov}} < 1\%\)) and balanced tails
(\(\Delta_{\text{tail}} < 2\%\)), enforced through a 3.0Ã— penalty
multiplier.

\textbf{Properties:} 

\begin{itemize}
\item
Maps coverage quality to expected confidence level
\item
Quadratic penalty for calibration mismatch
\item
Enhanced scrutiny for maximum confidence claims
\item
Proportional to interval width
\end{itemize}


\subsection{Balance Penalty}\label{balance-penalty}

\textbf{Definition:}

\[
P_{\text{balance}} = 1.0 \cdot (H - L) \cdot \left(\frac{\Delta_{\text{tail}}}{10}\right)^2
\]

where
\(\Delta_{\text{tail}} = |P_{\text{below}} - 5| + |P_{\text{above}} - 5|\).

\textbf{Rationale:} A well-specified 90\% CI should exhibit approximate
symmetry with 5\% in each tail. This component explicitly penalizes
imbalanced intervals, preventing gaming strategies where, for example, a
very tight lower bound compensates for an excessively loose upper bound
to achieve 10\% total outside. The penalty is applied universally,
independent of confidence level.

\textbf{Properties:} 

\begin{itemize}
\tightlist
\item
Quadratic in tail imbalance 
\item
Enforces symmetric coverage
\item
Independent of confidence calibration
\item
Coefficient 1.0 provides moderate weight
\end{itemize}


\subsection{Complete Scoring Function}\label{complete-scoring-function}

\subsection{Mathematical Specification}\label{mathematical-specification}

The complete scoring function for interval \([L, H]\) with confidence
\(c\) and dataset \(\mathcal{D} = \{x_1, \ldots, x_n\}\) is:

\[
\boxed{S(L, H, c \mid \mathcal{D}) = P_{\text{precision}} + P_{\text{miss}} + P_{\text{over}} + P_{\text{calib}} + P_{\text{balance}}}
\]

where all penalty components are defined as above. The score is rounded
to the nearest integer for reporting.

\subsection{Optimal Strategy}\label{optimal-strategy}

The scoring function incentivizes the following strategy:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Accuracy:} Match estimated bounds to actual sample percentiles (p5 and p95)
  constraints
\item
  \textbf{Coverage:} Achieve approximately 90\% empirical coverage
\item
  \textbf{Calibration:} Match claimed confidence to actual interval
  quality
\item
  \textbf{Balance:} Distribute coverage symmetry with 5\% in each tail
\item
  \textbf{Honesty:} Report confidence levels that reflect genuine
  uncertainty
\end{enumerate}

Deviations from any dimension incur quadratic penalties, with weights
tuned to prevent dominance by any single component.

\section{Illustrative Examples}\label{illustrative-examples}

\subsection{Example: Perfect Interval}\label{example-5.1-perfect-interval}

\textbf{Specifications:} 
\begin{itemize}
\item Sample percentiles: $p_5 = 1080$ seconds (18 min), $p_{95} = 1680$ seconds (28 min)
\item Estimated interval: $[L, H] = [1080, 1680]$ (exactly matching sample percentiles)
\item Empirical coverage: 90.2\% (4.8\% below, 5.0\% above)
\item Confidence: $c = 10$
\end{itemize}


\textbf{Penalty Calculation:} 
\begin{itemize}
\item \(P_{\text{precision}} = (1080 - 1080)^2 + (1680 - 1680)^2 = 0\) (perfect match!)
\item \(P_{\text{miss}} \approx 150\) (small residual from 9.8\% outside) 
\item \(P_{\text{over}} = 0\) (coverage \textless{} 95\%) 
\item \(P_{\text{calib}} \approx 0\) (\(\Delta_{\text{cov}} = 0.2 < 1\), \(\Delta_{\text{tail}} = 0.2 < 2\)) 
\item \(P_{\text{balance}} \approx 0.07\) (\(\Delta_{\text{tail}} = 0.2\))
\end{itemize}

\textbf{Total Score:} \(S \approx 150\)

\textbf{Interpretation:} Near-optimal performance with minimal penalties. 
The precision penalty is zero because the estimates perfectly match the sample percentiles.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{Example: Overconfident Estimate}\label{example-5.2-overconfident-estimate}

\textbf{Specifications:} 
\begin{itemize}
\item Sample percentiles: \(p_5 = 1080\) seconds, \(p_{95} = 1680\) seconds
\item Estimated interval: \([L, H] = [1200, 1800]\) (120 sec high on each bound)
\item Empirical coverage: 85\% (8\% below, 7\% above) 
\item Confidence: \(c = 10\)
\end{itemize}

\textbf{Penalty Calculation:} 
\begin{itemize}
\item \(P_{\text{precision}} = (1080 - 1200)^2 + (1680 - 1800)^2 = 14400\) (poor match!)
\item \(P_{\text{miss}} \approx 400\) (15\% outside)
\item \(P_{\text{over}} = 0\)
\item \(\Delta_{\text{cov}} = |15 - 10| = 5 > 1\)
\item \(\Delta_{\text{tail}} = |8-5| + |7-5| = 5 > 2\)
\item Interval width for other penalties: \(1800 - 1200 = 600\) seconds
\item \(P_{\text{calib}} = 3.0 \cdot 600 \cdot \left(\frac{5 + 5}{5}\right)^2 = 7200\) (heavy penalty)
\item \(P_{\text{balance}} = 1.0 \cdot 600 \cdot \left(\frac{5}{10}\right)^2 = 150\)
\end{itemize}

\textbf{Total Score:} \(S \approx 36550\)

\textbf{Interpretation:} Large precision penalty for poor boundary estimation, 
plus severe penalty for claiming perfection (confidence = 10) with poor actual performance.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\subsection{Example: Unbalanced Interval}\label{example-5.3-unbalanced-interval}

\textbf{Specifications:} 
\begin{itemize}
\item Sample percentiles: \(p_5 = 1080\) seconds, \(p_{95} = 1680\) seconds
\item Estimated interval: \([L, H] = [1050, 1730]\) (30 sec low, 50 sec high)
\item Empirical coverage: 90\% (2\% below, 8\% above)
\item Confidence: \(c = 9\)

\end{itemize}

\textbf{Penalty Calculation:} 
\begin{itemize}
\item \(P_{\text{precision}} = (1050 - 1080)^2 + (1730 - 1680)^2 = 900 + 2500 = 3400\) 
\item \(P_{\text{miss}} \approx 200\) - \(P_{\text{over}} = 0\) 
\item \(P_{\text{miss}} \approx 200\) - \(P_{\text{over}} = 0\) 
\item \(\Delta_{\text{cov}} = 0\) (10\% outside) - \(c_{\text{ideal}} = 10\), \(\Delta_c = 1\) 
\item Interval width: \(1730 - 1050 = 680\) seconds
\item \(P_{\text{calib}} = 2.0 \cdot 680 \cdot \left(\frac{1}{5}\right)^2 = 54\)
\item \(\Delta_{\text{tail}} = |2-5| + |8-5| = 6\)
\item \(P_{\text{balance}} = 1.0 \cdot 680 \cdot \left(\frac{6}{10}\right)^2 = 245\)
\end{itemize}

\textbf{Total Score:} \(S \approx 3899\)

\textbf{Interpretation:} Moderate penalty for tail imbalance and imperfect boundary estimation despite correct total coverage.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\subsection{Example: Honest Uncertainty}\label{example-5.4-honest-uncertainty}

\textbf{Specifications:} 
\begin{itemize}
\item
Sample percentiles: \(p_5 = 1080\) seconds, \(p_{95} = 1680\) seconds
\item
Estimated interval: \([L, H] = [900, 1900]\) (180 sec low, 220 sec high - very conservative)
\item
Empirical coverage: 75\% (12\% below, 13\% above)
\item
Confidence: \(c = 7\)
\end{itemize}

\textbf{Penalty Calculation:} 
\begin{itemize}
\item
\(P_{\text{precision}} = (900 - 1080)^2 + (1900 - 1680)^2 = 32400 + 48400 = 80800\)
\item
\(P_{\text{miss}} \approx 600\) - \(P_{\text{over}} = 0\) 
\item
\(\Delta_{\text{cov}} = |25 - 10| = 15\) 
\item
\(c_{\text{ideal}} = 10 - 15/10 = 8.5\), \(\Delta_c = 1.5\) 
\item
Interval width: \(1900 - 900 = 1000\) seconds
\item
\(P_{\text{calib}} = 2.0 \cdot 1000 \cdot \left(\frac{1.5}{5}\right)^2 = 180\)
\item
\(\Delta_{\text{tail}} = |12-5| + |13-5| = 15\)
\item
\(P_{\text{balance}} = 1.0 \cdot 1000 \cdot \left(\frac{15}{10}\right)^2 = 2250\)
\end{itemize}

\textbf{Total Score:} \(S \approx 83830\)

\textbf{Interpretation:} 
Very poor boundary estimation (large precision penalty) combined with poor interval quality, 
though relatively small calibration penalty due to appropriately modest confidence claim.

\section{Strengths and Limitations}\label{strengths-and-limitations}

\subsection{Strengths}\label{strengths}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Multi-dimensional Assessment:} The scoring system simultaneously evaluates estimation accuracy, 
  coverage, calibration, and balance, preventing optimization of any single dimension at the expense of others.
\item
  \textbf{Gaming Resistance:} Specific penalty components (overcoverage, balance) explicitly counter known 
  gaming strategies such as arbitrarily wide intervals or asymmetric bounds.
\item
  \textbf{Theoretical Grounding:} The quadratic penalty structure
  inherits desirable properties from Brier scoring, including proper
  scoring rule characteristics that encourage honest reporting.
\item
  \textbf{Interpretable Components:} Each penalty term corresponds to an
  intuitive quality dimension with clear physical interpretation.
\item
  \textbf{Calibration Incentive:} The confidence calibration component
  explicitly rewards self-awareness and penalizes overconfidence,
  promoting metacognitive skill development.
\item
  \textbf{Robustness:} The 10\% trimming in miss penalty calculation
  provides resilience to extreme outliers while maintaining sensitivity
  to systematic coverage failures.
\end{enumerate}

\subsection{Limitations}\label{limitations}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Parameter Sensitivity:} The relative weights of penalty
  components (0.5, 1.0, 2.0, 3.0) were chosen heuristically. Alternative
  weightings may produce different optimal strategies, and formal
  optimization of these hyperparameters remains an open question.
\item
  \textbf{Distributional Assumptions:} The 5\%-5\% tail balance target
  implicitly assumes approximate symmetry in the underlying
  distribution. For highly skewed commute time distributions, this
  requirement may be overly restrictive.
\item
  \textbf{Sample Size Dependence:} With small sample sizes (\(n \approx 20-30\)), 
  sample percentiles exhibit estimation variance.
  The scoring function does not explicitly account for this uncertainty in the target percentiles.
\item
  \textbf{Non-Convexity:} The piecewise nature of some penalty functions
  (e.g., overcoverage threshold) introduces discontinuities that may
  complicate optimization and interpretation near boundary regions.
\item
  \textbf{Scale Dependence:} Penalty magnitudes scale with interval
  width, which inherently depends on the time scale of the underlying
  data. Cross-dataset comparisons require careful normalization.
\item
  \textbf{Confidence Discretization:} Restricting confidence to integer
  values in \([5, 10]\) provides limited resolution for fine-grained
  calibration assessment. A continuous scale might better capture
  nuanced uncertainty. This needs to be balanced against the poor ability
  of most individuals to reliably distinguish small differences in confidence.
\item
  \textbf{Independence Assumption:} The additive penalty structure assumes independence among quality dimensions. 
  In practice, certain trade-offs are inevitable, and the optimal balance depends on the specific weight configuration.
\end{enumerate}

\subsection{Relation to Traditional Brier Scoring}\label{relation-to-traditional-brier-scoring}

Both the precision penalty ($P_{\text{precision}}$) and miss penalty 
($P_{\text{miss}}$) implement Brier's mean squared error principle:

\[
P_{\text{precision}} = (L - p_5)^2 + (H - p_{95})^2
\]


\[
P_{\text{miss}} = \frac{1}{n}\sum_{m \in \mathcal{M}'} m = \frac{1}{n}\sum_{m \in \mathcal{M}'} (\text{distance})^2
\]

This parallels the Brier score's \((f - o)^2\) formulation, where
forecast error is penalized quadratically. However, our extension
differs in several key aspects:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Continuous vs.~Binary:} We evaluate continuous interval bounds
  rather than binary event probabilities.
\item
  \textbf{Multiple Dimensions:} Traditional Brier scores measure a
  single forecast-outcome discrepancy, whereas our system assesses five
  distinct quality aspects.
\item
  \textbf{Subjective Calibration:} The confidence calibration component
  introduces a meta-level assessment of forecaster self-awareness,
  absent in standard Brier scoring.
\item
  \textbf{Structural Penalties:} Components like balance and
  overcoverage penalties enforce structural properties beyond simple
  accuracy.
\end{enumerate}

The quadratic penalty structure remains central: larger deviations are
disproportionately costly, encouraging forecasters to minimize expected
squared error across all dimensions. This maintains the proper scoring
rule philosophy that honest, well-calibrated estimates should minimize
expected penalty.

\section{Implementation Considerations}\label{implementation-considerations}

\subsection{Computational Complexity}\label{computational-complexity}

The scoring function requires \(O(n \log n)\) time due to sorting
operations in miss penalty calculation. For typical commute datasets
(\(n \approx 50-200\)), this is negligible. Space complexity is \(O(n)\)
for storing miss values.

\subsection{Numerical Stability}\label{numerical-stability}

All penalty calculations use floating-point arithmetic. Care must be
taken with: 
\begin{itemize}
\item
Division by zero when \(n = 0\) (handled by minimum record
requirement \(n \geq 20\)) 
\item
Overflow in squared distance calculations
for extreme outliers (mitigated by 10\% trimming)
\end{itemize}

\subsection{Verification and Reproducibility}\label{verification-and-reproducibility}

A cryptographic checksum mechanism is provided to verify score
integrity:

\[
\text{checksum} = \text{Hash}(L, H, S, c)
\]

where the hash function combines rounded parameter values into a
deterministic 32-bit signature. This enables external verification via
Excel VBA or other independent implementations, ensuring audit trail
integrity for competitive challenges.

\section{Conclusion}\label{conclusion}

We have presented a comprehensive scoring methodology for confidence
interval estimation that extends Brier scoring principles to
multi-dimensional interval quality assessment. The system effectively
balances competing objectives through weighted quadratic penalties while
explicitly countering gaming strategies. Through careful calibration of
penalty weights and special handling of extreme confidence claims, the
scoring function encourages honest, well-calibrated predictions with
balanced coverage.

The methodology demonstrates that proper scoring rules can be extended
beyond binary events to complex estimation tasks requiring simultaneous
optimization across multiple quality dimensions. Future work might
explore adaptive penalty weights based on sample size, explicit
uncertainty quantification in score reporting, and extensions to
non-symmetric target distributions.

\section{References}\label{references}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Brier, G. W. (1950). ``Verification of forecasts expressed in terms of
  probability.'' \emph{Monthly Weather Review}, 78(1), 1-3.
\item
  Gneiting, T., \& Raftery, A. E. (2007). ``Strictly proper scoring
  rules, prediction, and estimation.'' \emph{Journal of the American
  Statistical Association}, 102(477), 359-378.
\item
  Winkler, R. L. (1996). ``Scoring rules and the evaluation of
  probabilities.'' \emph{Test}, 5(1), 1-60.
\item
  Merkle, E. C., \& Steyvers, M. (2013). ``Choosing a strictly proper
  scoring rule.'' \emph{Decision Analysis}, 10(4), 292-304.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Document Version Control:} - v0.2 (2025-11-08): Initial
specification and mathematical formulation - Pre-Publication. Awaiting review.

\end{document}
